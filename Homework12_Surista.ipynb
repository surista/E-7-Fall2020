{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 12\n",
    "\n",
    "## Due 4PM Nov 30, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Women's 800 Meter\n",
    "\n",
    "Which countries have done best at the Women's 800 Meter?\n",
    "\n",
    "Gather the data from the World Records CSV, use a Dictionary to count the records, and create a bar chart showing the relative number of records per country.  Sort the countries alphabetically, and make sure we can read the country names.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "filename = \"WorldRecords.csv\"\n",
    "\n",
    "# read in data\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# filter to women's 800m\n",
    "df2 = df[(df['Event'] =='Womens 800m')]\n",
    "\n",
    "# create dict to count records\n",
    "nats = {}\n",
    "for index, row in df2.iterrows():\n",
    "    if row['Nationality'] not in nats:\n",
    "        nats[row['Nationality']] = 1\n",
    "    else:\n",
    "        nats[row['Nationality']] += 1\n",
    "\n",
    "# create & draw chart        \n",
    "nats = sorted(nats.items())\n",
    "x = [k[0] for k in nats]\n",
    "y = [k[1] for k in nats]\n",
    "\n",
    "plt.bar(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Regular Expressions\n",
    "\n",
    "We have used Beautiful Soup to scrape a website.\n",
    "\n",
    "Let's see what we can do with just urlib and Regular Expressions\n",
    "\n",
    "Take the DCE website, and find all the links.  (Be sure to compare notes with Beautiful Soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import string\n",
    "import re\n",
    "\n",
    "def find_links(url):\n",
    "    \"\"\"Returns the first URL and link txt on page\"\"\"\n",
    "\n",
    "    # read in url text\n",
    "    with urllib.request.urlopen(url) as f:\n",
    "        text = f.read().decode('utf-8')\n",
    "\n",
    "    re_links = re.findall('<a.*/a>', text)\n",
    "\n",
    "    return re_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = 'https://www.extension.harvard.edu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6721ebaeaac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwebsite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results1 = find_links(website)\n",
    "print(len(results))\n",
    "for link in results:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\"prettify print the html of a given url\"\n",
    "\n",
    "url = \"https://www.extension.harvard.edu\"\n",
    "html_content = requests.get(url).text\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "pretty_soup = soup.prettify()\n",
    "\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "print(\"link:\", links[0])\n",
    "print(\"results:\", results[0])\n",
    "\n",
    "print(\"Number of links:\",len(links),\"\\n\")\n",
    "for x in links:\n",
    "   print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(10):\n",
    "    print(results1[x],\"\\t\", links[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare your program with the results from Beautiful Soup\n",
    "\n",
    "Do you get the same number of links?  If not:\n",
    "\n",
    "1) How many do you miss?\n",
    "\n",
    "2) Can you explain why you miss them?\n",
    "\n",
    "3) Can you fix it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: File Name Generator\n",
    "\n",
    "Write a Generator that takes a directory, a file extension, and, optionally, a file size, and then yields a stream of tuples, (path, filename) so that path/filename is a legal path to a file that meets the conditions.\n",
    "\n",
    "Use os.walk(dir) to create a generator that gives all files and directories below dir.  Call this generator, and yield files (not directories) with the right extension and a file size greater than the given size.   \n",
    "\n",
    "We have three unit tests: demonstrate that you can walk recursivly through two or more directories, and that you can filter by file extension and filter by extension and by size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('../E-7-Fall2020/Homework12_Surista.ipynb', 54076), ('../E-7-Fall2020/Day08/Day8.ipynb', 43290), ('../E-7-Fall2020/Day08/CopyBox.jpg', 52884), ('../E-7-Fall2020/Day08/.ipynb_checkpoints/Day8-checkpoint.ipynb', 43290), ('../E-7-Fall2020/Day07/Day7.ipynb', 61025), ('../E-7-Fall2020/Day11/Homework11_SUrista.ipynb', 41789), ('../E-7-Fall2020/Day11/.ipynb_checkpoints/Homework11-checkpoint.ipynb', 41729), ('../E-7-Fall2020/Day11/.ipynb_checkpoints/Homework11_original-checkpoint.ipynb', 41848), ('../E-7-Fall2020/Day11/.ipynb_checkpoints/Homework11_SUrista-checkpoint.ipynb', 41789), ('../E-7-Fall2020/Day11/.ipynb_checkpoints/Homework11SUrista-checkpoint.ipynb', 43057), ('../E-7-Fall2020/Day02/Day2.ipynb', 40949), ('../E-7-Fall2020/.ipynb_checkpoints/Homework12_Surista-checkpoint.ipynb', 53638), ('../E-7-Fall2020/Day06/pywiki.txt', 46990), ('../E-7-Fall2020/Day06/pytext.txt', 49208), ('../E-7-Fall2020/Day06/Day6.ipynb', 73647), ('../E-7-Fall2020/Day12/.ipynb_checkpoints/Homework12_Surista-checkpoint.ipynb', 44408), ('../E-7-Fall2020/Day10/Homework10_S_Urista.ipynb', 43354), ('../E-7-Fall2020/Day10/BeautifulSoup-Lena.ipynb', 991090), ('../E-7-Fall2020/Day10/Homework10.ipynb', 42601), ('../E-7-Fall2020/Day10/.ipynb_checkpoints/Homework10-checkpoint.ipynb', 35055), ('../E-7-Fall2020/Day10/.ipynb_checkpoints/Homework10 (4)-checkpoint.ipynb', 43354), ('../E-7-Fall2020/Day10/.ipynb_checkpoints/2016_US_County_Level_Presidential_Results-checkpoint.ipynb', 98033), ('../E-7-Fall2020/Day04/Day4 (1).ipynb', 60195), ('../E-7-Fall2020/Day04/.ipynb_checkpoints/Day4-checkpoint.ipynb', 60057), ('../E-7-Fall2020/Day04/.ipynb_checkpoints/Day4 (1)-checkpoint.ipynb', 60195), ('../E-7-Fall2020/Day09/Iterator (1).ipynb', 52895), ('../E-7-Fall2020/Day09/.ipynb_checkpoints/Day10-checkpoint.ipynb', 46483), ('../E-7-Fall2020/Day09/.ipynb_checkpoints/Iterator-checkpoint.ipynb', 115049), ('../E-7-Fall2020/Day05/Day5.ipynb', 61784)]\n",
      "<generator object find_files_gen at 0x7f67b9748dd0>\n",
      "<generator object find_files_gen at 0x7f67b9748dd0>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def find_files_gen(path, filename, filesize=0):\n",
    "    matches = []\n",
    "    for root,dir, files in os.walk(path):\n",
    "        for f in files:\n",
    "            path = os.path.join(root, f)\n",
    "            size = os.stat(path).st_size\n",
    "            if filename in f and size > filesize:\n",
    "                matches.append((root+\"/\"+f, size))\n",
    "    yield matches\n",
    "    \n",
    "gen = find_files_gen('..', 'py',35000)\n",
    "print(next(gen))\n",
    "print(gen)\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-92187c19f3e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_files_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'py'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m35000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Show recursive search.  Make sure we can see at least two directories of files\n",
    "gen = find_files_gen('..', 'py',35000)\n",
    "\n",
    "for path, filename in gen:\n",
    "    print(path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-10f13b69d69e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_files_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.ipynb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Show all notebooks in this directory\n",
    "gen = find_files_gen('.', '.ipynb')\n",
    "\n",
    "for path, filename in gen:\n",
    "    print(path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4cf2c2040bf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_files_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.ipynb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Show all notebooks in this directory with at least 1K bytes\n",
    "gen = find_files_gen('.', '.ipynb', 1000)\n",
    "\n",
    "for path, filename in gen:\n",
    "    print(path, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Sorting Employees\n",
    "\n",
    "We wish to take an unordered list of Employees, and get a list sorted by Company and Id.\n",
    "\n",
    "Everyone who works at 'Springfield Department of Motor Vehicles' should be in one group. \n",
    "Everyone who works at 'Springfield Nuclear Power' would be in another group, later in the list, \n",
    "and everyone who works from the Mafia would be in a group earlier in the list. \n",
    "Within each group, we want to see the low ID numbers before this high ones.\n",
    "\n",
    "For this problem, we do not want you to write a sorting program. You will use Python's sort.   \n",
    "You just need to define the magic method dunder lt(), less than, for the class Employee. \n",
    "\n",
    "Once you have defined dunder lt(), calling Python's sorted() on a list of Employees will return a sorted list.\n",
    "\n",
    "### Add to the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "\n",
    "    def __init__(self, first, last):\n",
    "        self.firstname = first.capitalize()\n",
    "        self.lastname = last.capitalize()\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.firstname + \" \" + self.lastname\n",
    "\n",
    "\n",
    "class Employee(Person):\n",
    "\n",
    "    def __init__(self, first, last, company, id):\n",
    "        # Call Superclass to set common information\n",
    "        super().__init__(first, last)\n",
    "        self.id = id\n",
    "        self.company = company\n",
    "\n",
    "    def __str__(self):\n",
    "        # Call Superclass to dispaly common information\n",
    "        return super().__str__() + \", \" + str(self.id) + ' at ' + self.company\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        \"Is self less than other?\"\n",
    "        \n",
    "        if not isinstance(other, Employee):\n",
    "            return False\n",
    "        return (self.company, self.id) < (other.company, other.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homer Simpson, 1005 at Springfield Nuclear Power\n",
      "Barney Gumble, 1 at Plow King\n",
      "Clancy Wiggum, 1 at Police Department\n",
      "Edna Krabapple, 39 at Springfield Elementary School\n",
      "Seymour Skinner, 1 at Springfield Elementary School\n",
      "Charles Burns, 1 at Springfield Nuclear Power\n",
      "Waylon Smithers, 2 at Springfield Nuclear Power\n",
      "Patty Bouvier, 39 at Springfield Department of Motor Vehicles\n",
      "Selma Bouvier, 38 at Springfield Department of Motor Vehicles\n",
      "Robert Terwilliger, 31 at Channel 6\n",
      "Herschel Krustofsky, 2 at Channel 6\n",
      "Lois Pennycandy, 46 at Channel 6\n",
      "Johnny Cevasco, 2 at Mafia\n",
      "Fat Tony, 1 at Mafia\n",
      "Max Legman, 3 at Mafia\n",
      "Louie Walters, 4 at Mafia\n",
      "==========================\n",
      "Herschel Krustofsky, 2 at Channel 6\n",
      "Robert Terwilliger, 31 at Channel 6\n",
      "Lois Pennycandy, 46 at Channel 6\n",
      "Fat Tony, 1 at Mafia\n",
      "Johnny Cevasco, 2 at Mafia\n",
      "Max Legman, 3 at Mafia\n",
      "Louie Walters, 4 at Mafia\n",
      "Barney Gumble, 1 at Plow King\n",
      "Clancy Wiggum, 1 at Police Department\n",
      "Selma Bouvier, 38 at Springfield Department of Motor Vehicles\n",
      "Patty Bouvier, 39 at Springfield Department of Motor Vehicles\n",
      "Seymour Skinner, 1 at Springfield Elementary School\n",
      "Edna Krabapple, 39 at Springfield Elementary School\n",
      "Charles Burns, 1 at Springfield Nuclear Power\n",
      "Waylon Smithers, 2 at Springfield Nuclear Power\n",
      "Homer Simpson, 1005 at Springfield Nuclear Power\n",
      "\n",
      "\tSuccess!\n"
     ]
    }
   ],
   "source": [
    "lst = [\n",
    "    Employee('Homer', 'Simpson', 'Springfield Nuclear Power', 1005),\n",
    "    Employee('Barney', 'Gumble', 'Plow King', 1),\n",
    "    Employee('Clancy', 'Wiggum', 'Police Department', 1),\n",
    "    Employee('Edna', 'Krabapple', 'Springfield Elementary School', 39),\n",
    "    Employee('Seymour', 'Skinner', 'Springfield Elementary School', 1),\n",
    "    Employee('Charles', 'Burns', 'Springfield Nuclear Power', 1),\n",
    "    Employee('Waylon', 'Smithers', 'Springfield Nuclear Power', 2),\n",
    "    Employee('Patty', 'Bouvier', 'Springfield Department of Motor Vehicles', 39),\n",
    "    Employee('Selma', 'Bouvier', 'Springfield Department of Motor Vehicles', 38),\n",
    "    Employee('Robert', 'Terwilliger', 'Channel 6', 31),\n",
    "    Employee('Herschel', 'Krustofsky', 'Channel 6', 2),\n",
    "    Employee('Lois', 'Pennycandy', 'Channel 6', 46),\n",
    "    Employee('Johnny', 'Cevasco', 'Mafia', 2),\n",
    "    Employee('Fat', 'Tony', 'Mafia', 1),\n",
    "    Employee('Max', 'Legman', 'Mafia', 3 ),\n",
    "    Employee('Louie', 'Walters', 'Mafia', 4)\n",
    "    ]\n",
    "\n",
    "for emp in lst:\n",
    "    print(emp)\n",
    "    \n",
    "print('==========================')\n",
    "\n",
    "# Sort the people\n",
    "lst = sorted(lst)\n",
    "\n",
    "# Now check that the list is sorted\n",
    "for first, second in zip(lst[:-1], lst[1:]):\n",
    "    assert (first.company, first.id) < (second.company, second.id)\n",
    "\n",
    "for emp in lst:\n",
    "    print(emp)\n",
    "    \n",
    "print(\"\\n\\tSuccess!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Finding Repeats\n",
    "\n",
    "DNA has a great deal of structure.  DNA often contains repeats: this is a fascinating area that we are not going to explore.  Investigate 'transposons'.  \n",
    "    \n",
    "Write a program that finds the longest repeat in a sequence of DNA stored in a FASTA file.\n",
    "\n",
    "There will be a single string of DNA in the file. The first line has a description of the contents,\n",
    "while the remainder is a string of A, C, G, and T with line breaks.  Be sure to remove the line breaks.  \n",
    "\n",
    "Here is a sample run on pKLMF-FX.fasta\n",
    "\n",
    "```python\n",
    "10089\n",
    "(5535, 5541, 15)\n",
    "CACGGGCACGGGCAC\n",
    "CACGGGCACGGGCAC\n",
    "CPU times: user 191 ms, sys: 2.49 ms, total: 193 ms\n",
    "Wall time: 193 ms\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read contents of fasta file with a single sequence\n",
    "# Skip the first line, and return a string holding the contents\n",
    "\n",
    "import re\n",
    "\n",
    "def read_fasta_file(filename: str) -> str:\n",
    "    with open(filename, 'r') as f:\n",
    "        temp = [line.strip() for line in f]\n",
    "        seq = ''.join(temp[1:])\n",
    "        \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a string and look for the longest repeat\n",
    "# Return a tuple: (pos1, pos2, length) or None if there are no repeats\n",
    "#    pos1 != pos2 and text[pos1:pos1+length)] == text[pos2:pos2+length]\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def longest_repeat(text):\n",
    "\n",
    "    sol = (0,0,0)\n",
    "    count = 2\n",
    "    while True:\n",
    "\n",
    "        d = defaultdict(list)\n",
    "        for i in range(len(text)):\n",
    "            d[text[i:i+count]].append(i)\n",
    "        del_list = [(item, d[item]) for item in d if len(item) > 1 and len(d[item]) > 1]\n",
    "        if len(del_list) == 0:\n",
    "            return sol\n",
    "        else:\n",
    "            temp = [(item[1][0], item[1][1], len(item[0])) for item in del_list]\n",
    "            sol = (temp[0][0], temp[0][1], temp[0][2])\n",
    "            \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9988\n",
      "(5434, 5440, 15)\n",
      "CACGGGCACGGGCAC\n",
      "CACGGGCACGGGCAC\n",
      "CPU times: user 54.2 ms, sys: 24 µs, total: 54.2 ms\n",
      "Wall time: 54.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filename = 'pKLMF-FX.fasta'\n",
    "\n",
    "text = read_fasta_file(filename)\n",
    "print(len(text))               \n",
    "assert len(text) == 9988\n",
    "\n",
    "tup = longest_repeat(text) \n",
    "\n",
    "print(tup)\n",
    "assert len(tup) == 3\n",
    "assert isinstance(tup, tuple)\n",
    "\n",
    "print(text[tup[0]:tup[0]+tup[2]])\n",
    "print(text[tup[1]:tup[1]+tup[2]])\n",
    "\n",
    "assert text[tup[0]:tup[0]+tup[2]] == text[tup[1]:tup[1]+tup[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4245\n",
      "(2180, 3274, 94)\n",
      "AGCTCCTTCCGGTGGGCGCGGGGCATGACTATCGTCGCCGCACTTATGACTGTCTTCTTTATCATGCAACTCGTAGGACAGGTGCCGGCAGCGC\n",
      "AGCTCCTTCCGGTGGGCGCGGGGCATGACTATCGTCGCCGCACTTATGACTGTCTTCTTTATCATGCAACTCGTAGGACAGGTGCCGGCAGCGC\n",
      "CPU times: user 152 ms, sys: 304 µs, total: 152 ms\n",
      "Wall time: 153 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filename = 'pACYC184.fasta'        # An EColi plasmid cloning vector\n",
    "\n",
    "# See https://www.snapgene.com/resources/plasmid-files/?set=basic_cloning_vectors&plasmid=pACYC184\n",
    "    \n",
    "\n",
    "text = read_fasta_file(filename)\n",
    "print(len(text))                   # DNA is 4289 Bytes long: remove first line and \\n\n",
    "assert len(text) == 4245 \n",
    "\n",
    "tup = longest_repeat(text) \n",
    "print(tup)\n",
    "assert len(tup) == 3\n",
    "assert isinstance(tup, tuple)\n",
    "\n",
    "print(text[tup[0]:tup[0]+tup[2]])\n",
    "print(text[tup[1]:tup[1]+tup[2]])\n",
    "\n",
    "assert tup[2] == 94\n",
    "assert text[tup[0]:tup[0]+tup[2]] == text[tup[1]:tup[1]+tup[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra credit: Find the longest repeat in EColi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4641652\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filename = 'ecoli.fasta'\n",
    "\n",
    "text = read_fasta_file(filename)\n",
    "print(len(text))\n",
    "assert len(text) == 4641652\n",
    "\n",
    "tup = longest_repeat(text)  \n",
    "print(tup)\n",
    "\n",
    "assert len(tup) == 3\n",
    "assert isinstance(tup, tuple)\n",
    "assert len(text) == 4641729 \n",
    "\n",
    "print(text[tup[0]:tup[0]+tup[2]])\n",
    "print(text[tup[1]:tup[1]+tup[2]])\n",
    "\n",
    "assert text[tup[0]:tup[0]+tup[2]] == text[tup[1]:tup[1]+tup[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
